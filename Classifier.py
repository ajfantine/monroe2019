'''
Classifies headlines as either real (1) or fake (0), trained on 50,000 fake headlines
generated by the Generator class and 50,000 real headlines from the first file in 
the all-the-news dataset.

Author: Alex Fantine
'''

import string, os
from collections import OrderedDict
from keras.preprocessing.sequence import pad_sequences
from keras.layers import Dense
from keras.models import Sequential, load_model
from keras.preprocessing.text import Tokenizer
import pandas as pd
import numpy as np
import random

class Classifier:
    def __init__(self):
        self.model = load_model("revised-headline-classifier-v2.model")

        train_x, train_y, self.test_x, self.test_y, self.max_seq_len, \
        self.tokenizer = self.preprocess()

        print('max seq len: ', self.max_seq_len)

    '''
    This method prepares all the necessary ingredients for the model, starting with
    reading in the raw headline text and converting it to integer sequences, then labeling real
    headlines with 1 and fake headlines with 0.

    Return: the training x and y data (headlines as integers and their labels)
    the testing x and y
    the largest headline length for padding purposes
    the tokenizer used to store the string:int dictionary
    '''
    def preprocess(self):
        real_headlines = []
        article_df = pd.read_csv('./all-the-news/articles1.csv')
        for i in range(len(article_df)):
            real_headlines.append(article_df.title[i])
        #arrays are not inherently mutable so use index to changes values
        for i in range(len(real_headlines)):
            #you can lowercase an entire string, it doesn't have to be word by word
            real_headlines[i] = "".join(v for v in real_headlines[i] if v not in string.punctuation).lower()
            real_headlines[i] = real_headlines[i].encode("utf8").decode("ascii", 'ignore')
            real_headlines[i] = real_headlines[i].replace("the new york times", "")
            real_headlines[i] = real_headlines[i].replace("breitbart", "")
        random.seed(13)
        random.shuffle(real_headlines)

        #read in the fake headlines
        files = ['1', '2', '3', '4', '5']
        fake_headlines = []
        for f in files:
            filename = open('gen_headlines_v2_' + f + '.txt', 'r')
            raw = ''.join([word for word in filename])
            fh_subset = raw.split('\n')
            fh_subset.pop(len(fh_subset)-1)
            fake_headlines += fh_subset
        #still using seed 13
        random.shuffle(fake_headlines)

        headline_dict = OrderedDict()
        for line in real_headlines:
            headline_dict[line] = 1

        for line in fake_headlines:
            headline_dict[line] = 0

        keys = list(headline_dict.keys())

        random.shuffle(keys)
        random_headline_dict = OrderedDict()
        for k in keys:
            random_headline_dict[k] = headline_dict[k]

        x = []
        y = []
        for line, label in random_headline_dict.items():
            x.append(line)
            y.append(label)

        tokenizer = Tokenizer()
        tokenizer.fit_on_texts(x)

        new_x = []
        for line in x:
            token_list = tokenizer.texts_to_sequences([line])[0]
            new_x.append(token_list)

        max_seq_len = max([len(seq) for seq in new_x])

        inp_x = np.array(pad_sequences(new_x, maxlen=max_seq_len))

        index = int(.9 * len(x))

        train_x = inp_x[:index]
        test_x = inp_x[index:]

        train_y = np.array(y[:index])
        test_y = np.array(y[index:])

        return train_x, train_y, test_x, test_y, max_seq_len, tokenizer

    #build the model, saved as 'revised-headline-classifier-v2.model'
    def build_model(self, x, y):
        total_words = len(tokenizer.word_index) + 1

        model = Sequential()

        model.add(Embedding(input_dim = total_words, output_dim = 128, input_length = max_seq_len))

        model.add(LSTM(units=128))
        model.add(Dropout(0.2))

        model.add(Dense(1, activation= 'sigmoid'))

        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])

        model.fit(x, y, epochs=50, batch_size=100, verbose = 2)

        model.save('revised-headline-classifier-v2.model')

    #turns the sentence back into strings from a padded integer sequence
    def print_sent(self, tokenizer, sentences):
        for sent in sentences:
            complete = ""
            for token in sent:
                if token != 0:
                    for word, index in tokenizer.word_index.items():
                        if index == token:
                            complete += word + " "
            return complete

    '''
    Returns lists containing all the false positives and false negatives the classifier
    predicted, where each element is a 3-item list containing the predicted value, the actual
    value, and the sentence as a string.

    predicted: array of predictions for the data
    x: the input component of the data
    y: the labels for the data, 1 if real, 0 if false
    tokenizer: the tokenizer used for matching word to ints, padding sequences, etc
    '''
    def generate_error_report(self, predicted, x, y, tokenizer, false_pos_only):
        false_neg = []
        false_pos = []
        for i in range(len(predicted)):
            full_info = [0,0,0]
            pred = predicted[i]
            if pred < .5:
                pred = 0
            elif pred >= .5:
                pred = 1
            if pred != y[i]:
                complete = ""

                if pred == 0 and y[i] == 1:
                    if false_pos_only:
                        pass
                    else:
                        full_info[0] = predicted[i]
                        full_info[1] = y[i]
                        full_info[2] = self.print_sent(tokenizer, [x[i]])
                        false_neg.append(full_info)

                elif pred == 1 and y[i] == 0:
                    full_info[0] = predicted[i][0]
                    full_info[1] = y[i]
                    full_info[2] = x[i][0] + ': ' + str(x[i][1])
                    if full_info not in false_pos:
                        false_pos.append(full_info)

        if false_pos_only:
            return false_pos
        return false_pos, false_neg

if __name__ == '__main__':
    pass
